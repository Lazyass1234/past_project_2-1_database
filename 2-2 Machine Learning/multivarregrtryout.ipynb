{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.svg\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "board = chess.Board()\n",
    "SVG(chess.svg.board(board=board,size=400)) #show board at jupyter notebook\n",
    "\n",
    "import pandas as pd\n",
    "chess_game = pd.read_csv(\"dataset/games.csv\", index_col=0)\n",
    "\n",
    "dataset = []\n",
    "#for i in range(1000):\n",
    "for i in range(len(chess_game)):\n",
    "    x = chess_game.iloc[i][11]\n",
    "    x = x.split()\n",
    "    array_move = []\n",
    "    for j in range(349):\n",
    "        list_square = []\n",
    "        \n",
    "        if len(x) < j+1:\n",
    "            \n",
    "            array_move.append([-1,-1])\n",
    "        else:\n",
    "            a = board.push_san(x[j])\n",
    "            list_square.append(a.from_square)\n",
    "            list_square.append(a.to_square)\n",
    "            array_move.append(list_square)\n",
    "    dataset.append(array_move)\n",
    "    board = chess.Board()\n",
    "    #print(\"%d 번째\"%i, \"게임 코드\", array_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 w1: 0.001 w2: 0.001 w3: 0.005 b: 0.000 Cost: 277.912598\n",
      "Epoch  100/1000 w1: 0.055 w2: 0.077 w3: 0.369 b: 0.009 Cost: 132.083099\n",
      "Epoch  200/1000 w1: 0.081 w2: 0.113 w3: 0.583 b: 0.014 Cost: 82.700829\n",
      "Epoch  300/1000 w1: 0.091 w2: 0.128 w3: 0.709 b: 0.018 Cost: 65.793823\n",
      "Epoch  400/1000 w1: 0.093 w2: 0.132 w3: 0.785 b: 0.021 Cost: 59.870506\n",
      "Epoch  500/1000 w1: 0.091 w2: 0.129 w3: 0.831 b: 0.023 Cost: 57.697861\n",
      "Epoch  600/1000 w1: 0.088 w2: 0.124 w3: 0.859 b: 0.025 Cost: 56.832031\n",
      "Epoch  700/1000 w1: 0.083 w2: 0.117 w3: 0.877 b: 0.027 Cost: 56.440292\n",
      "Epoch  800/1000 w1: 0.079 w2: 0.110 w3: 0.888 b: 0.028 Cost: 56.233856\n",
      "Epoch  900/1000 w1: 0.074 w2: 0.103 w3: 0.896 b: 0.029 Cost: 56.108845\n",
      "Epoch 1000/1000 w1: 0.071 w2: 0.097 w3: 0.901 b: 0.031 Cost: 56.025345\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x1_train = torch.FloatTensor(dataset[0])\n",
    "x2_train = torch.FloatTensor(dataset[1])\n",
    "x3_train = torch.FloatTensor(dataset[2])\n",
    "y_train = torch.FloatTensor(dataset[3])\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([w1,w2,w3,b], lr=1e-5)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 349, 2])\n",
      "torch.Size([1, 349, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_raw = np.array(dataset[0:1000])\n",
    "#x_raw = x_raw.transpose([1,2,0])\n",
    "y_raw = [np.array(dataset[11554])]\n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor(x_raw)\n",
    "y_train = torch.FloatTensor(y_raw)# which has full m349 moves, 13859 as well\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((1000, 1,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 2 at dimension 1, but got size 1 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-f03c12fb639e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mhypothesis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor to have size 2 at dimension 1, but got size 1 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
